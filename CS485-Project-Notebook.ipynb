{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40301bd7",
   "metadata": {},
   "source": [
    "\n",
    "![logo](./kfupm-logo.png)\n",
    "## <center> ICS 485: Machine Learning\n",
    "### <center> <font color=crimson> App Review Classification\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c79146",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "         <font color=\"pink\" size=5> Team Members\n",
    "        \n",
    "        # Mawiah Alboainain\n",
    "        # Yousef Alzahrani\n",
    " <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e51b01",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "    \n",
    "Table of Contents\n",
    "* [Exploratory Analysis](#first-bullet)\n",
    "* [Imbalanced Data](#fourth-bullet)\n",
    "* [Evaluation Measures](#fifth-bullet)\n",
    "* [Classifiers](#sixth-bullet)\n",
    "* [Hyper-parameter Tuning ](#seventh-bullet)\n",
    "* [Error Analysis](#eighth-bullet)\n",
    "* [Results](#ninth-bullet)\n",
    "* [Conclusion](#tenth-bullet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7104ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#text editing libraries\n",
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74838e",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f1cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",str(text)) #force string\n",
    "    text = re.sub(r\"(^|\\W)\\d+\", \"\", text)\n",
    "    text = text.lower()\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    text=word_tokenize(text)\n",
    "    tmp =''\n",
    "    for word in text:\n",
    "        tmp+=lemmatizer.lemmatize(word)+' '\n",
    "    text = tmp\n",
    "    \n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826a5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet',aug_max=10)   \n",
    "def text_augment(text):\n",
    "    return aug.augment(text,n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7fa288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(df):\n",
    "    classes = df.label.value_counts().to_dict()\n",
    "    downsize = min(classes.values())\n",
    "    classes_list = []\n",
    "    for key in classes:\n",
    "        classes_list.append(df[df['label'] == key]) \n",
    "    classes_sample = []\n",
    "    for i in range(0,len(classes_list)):\n",
    "        classes_sample.append(classes_list[i].sample(downsize, replace=True))\n",
    "    df_maybe = pd.concat(classes_sample)\n",
    "    final_df = pd.concat([df_maybe], axis=0)\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15a38c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(df):\n",
    "    classes = df.label.value_counts().to_dict()\n",
    "    most = max(classes.values())\n",
    "    to_augment =  max(classes.values()) - np.array(list(classes.values()))\n",
    "    classes_list = []\n",
    "    for key in classes:\n",
    "        classes_list.append(df[df['label'] == key]) \n",
    "    classes_sample = []\n",
    "    for i in range(1,len(classes_list)):\n",
    "        to_paraphrase = classes_list[i].sample(to_augment[i], replace=True)\n",
    "        to_paraphrase.review = to_paraphrase.apply(lambda x: text_augment(x['review']), axis=1)\n",
    "        classes_sample.append(to_paraphrase)\n",
    "    df_maybe = pd.concat(classes_sample)\n",
    "    final_df = pd.concat([df_maybe,classes_list[0],classes_list[1],classes_list[2],classes_list[3]], axis=0)\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cea40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://raw.githubusercontent.com/ZYousef/CS485-Project/main/AppReviews-FourClasses.csv\"\n",
    "df = pd.read_csv(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7da152",
   "metadata": {},
   "source": [
    "## <center><font color=purple> 1. Exploratory Data Analysis<a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a8cbe",
   "metadata": {},
   "source": [
    "### <font color=blue> A. Dataset Analysis & Important Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc8f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset analysis and report on important statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c25050",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Besides the occasional crash, this is an amazi...</td>\n",
       "      <td>Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This could be a great app if it was predictabl...</td>\n",
       "      <td>Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't open since the last 2 updates Pop-ups ...</td>\n",
       "      <td>Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use to love this app but it's not working afte...</td>\n",
       "      <td>Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urrrrm\\tAfter my third re installing, it final...</td>\n",
       "      <td>Bug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  Besides the occasional crash, this is an amazi...   Bug\n",
       "1  This could be a great app if it was predictabl...   Bug\n",
       "2  I can't open since the last 2 updates Pop-ups ...   Bug\n",
       "3  Use to love this app but it's not working afte...   Bug\n",
       "4  Urrrrm\\tAfter my third re installing, it final...   Bug"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ef7e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3733</td>\n",
       "      <td>3733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3217</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Good</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>15</td>\n",
       "      <td>2461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review   label\n",
       "count    3733    3733\n",
       "unique   3217       4\n",
       "top      Good  Rating\n",
       "freq       15    2461"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efdb2d",
   "metadata": {},
   "source": [
    "We have 3733 reviews, 3217 of them are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421ee743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3733 entries, 0 to 3732\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  3733 non-null   object\n",
      " 1   label   3733 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 58.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4d50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples,classes=df.shape[0],df.nunique()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4186f398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples,classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ade5e8",
   "metadata": {},
   "source": [
    "We have 3733 Samples & 4 unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fe4fe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating            2461\n",
       "UserExperience     607\n",
       "Bug                370\n",
       "Feature            295\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8dbb5",
   "metadata": {},
   "source": [
    "Rating, UserExperience, Bug & Features are the four unique classes. We can also notice an imbalance in classes with Rating dominating by a large margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11c61bd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1491, 238)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some reviews contains special string such as \\t & \\n for tabs and new line\n",
    "df[df.review.str.contains(\"\\t\")].shape[0],df[df.review.str.contains(\"\\n\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed4672d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.str.replace(\"\\n\",\" \")\n",
    "df.review = df.review.str.replace(\"\\t\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb6524c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.review.str.contains(\"\\t\")].shape[0],df[df.review.str.contains(\"\\n\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9616465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>The white app icon is so atrocious, I'm hiding...</td>\n",
       "      <td>Bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Nice</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Good Good</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Good</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Ok</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>Good Cool</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>Ok Ok</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>Great app</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>Ok</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>Excellent Excellent</td>\n",
       "      <td>Rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review   label\n",
       "223   The white app icon is so atrocious, I'm hiding...     Bug\n",
       "714                                                Nice  Rating\n",
       "752                                           Good Good  Rating\n",
       "786                                                Good  Rating\n",
       "820                                                  Ok  Rating\n",
       "...                                                 ...     ...\n",
       "3060                                          Good Cool  Rating\n",
       "3063                                              Ok Ok  Rating\n",
       "3075                                          Great app  Rating\n",
       "3085                                                 Ok  Rating\n",
       "3095                                Excellent Excellent  Rating\n",
       "\n",
       "[138 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dealing with duplicated data\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9ec7b",
   "metadata": {},
   "source": [
    "We notice 137 entries are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b50bd0e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c5ba7d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3862e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.label.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6bc0807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating            2324\n",
       "UserExperience     607\n",
       "Bug                369\n",
       "Feature            295\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0801c2d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating            2324\n",
       "UserExperience     607\n",
       "Bug                369\n",
       "Feature            295\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64299b2",
   "metadata": {},
   "source": [
    "## <center><font color=purple>4. Imbalanced Data<a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc3d25",
   "metadata": {},
   "source": [
    "**The next few cells is method used in dealing with imbalanced data**\n",
    "\n",
    "<font color=purple>\n",
    "    \n",
    "We've attempted 5 different blanacing techniques, simple Undersampling & Oversampling, Random Undersampling & Oversampling, and finally text augmentation using a paraphrasing library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f649902d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3684"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Blanaces the data and makes sure new aguments data duplicates are <=25 or reached limit\n",
    "df_balanced = oversample(df)\n",
    "dups = df_balanced.duplicated().sum()\n",
    "num_iter=0\n",
    "while num_iter < 10 & dups > 25 :\n",
    "    df_balanced.drop_duplicates(inplace=True)\n",
    "    df_balanced = oversample(df)\n",
    "    dups = df_balanced.duplicated().sum()\n",
    "    num_iter+=1\n",
    "#Make sure original dataset is embedded \n",
    "pd.merge(df,df_balanced,how='inner').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad2a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.to_csv('balanced.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d7a9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.read_csv('balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b56ea6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserExperience    2324\n",
       "Bug               2324\n",
       "Feature           2324\n",
       "Rating            2324\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912316af",
   "metadata": {},
   "source": [
    "**All classes with the same amount of data (2324)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d5dd8c",
   "metadata": {},
   "source": [
    "### <font color=blue> B. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92e29bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.review = df_balanced.apply(lambda x: clean_text(x['review']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "101bc142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bug</th>\n",
       "      <td>2324.0</td>\n",
       "      <td>40.406196</td>\n",
       "      <td>36.205128</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <td>2324.0</td>\n",
       "      <td>37.811102</td>\n",
       "      <td>35.534369</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>2324.0</td>\n",
       "      <td>13.885972</td>\n",
       "      <td>19.373360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserExperience</th>\n",
       "      <td>2324.0</td>\n",
       "      <td>33.649312</td>\n",
       "      <td>30.247588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count       mean        std  min   25%   50%   75%    max\n",
       "label                                                                     \n",
       "Bug             2324.0  40.406196  36.205128  2.0  19.0  31.0  49.0  278.0\n",
       "Feature         2324.0  37.811102  35.534369  3.0  18.0  29.5  45.0  277.0\n",
       "Rating          2324.0  13.885972  19.373360  0.0   3.0   7.0  17.0  272.0\n",
       "UserExperience  2324.0  33.649312  30.247588  1.0  13.0  25.0  45.0  260.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['review'].str.lower().str.split().apply(len).groupby(df_balanced.label).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95637fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_balanced['review'].str.lower().str.split().apply(len).groupby(df_balanced.label).hist(legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37c879",
   "metadata": {},
   "source": [
    "#### Ratings review are relatively short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d556f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['label_id'] = df_balanced['label'].factorize()[0] #digitze? label to int\n",
    "label_id_df_balanced = df_balanced[['label', 'label_id']].sort_values('label_id') #sort\n",
    "label_to_id = dict(label_id_df_balanced.values)\n",
    "id_to_label = dict(label_id_df_balanced[['label_id', 'label']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c08908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = df_balanced['review'], df_balanced['label']\n",
    "trainx, testx, trainy, testy = train_test_split(X, Y, test_size=0.3, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d1bcf2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6507, 48595)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text represntation\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(trainx).toarray()\n",
    "labels = trainy.factorize()[0]\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d1772c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Bug':\n",
      "  . Most correlated unigrams:\n",
      ". love\n",
      ". game\n",
      "  . Most correlated bigrams:\n",
      ". whatsapp sm\n",
      ". useful easy\n",
      "# 'Feature':\n",
      "  . Most correlated unigrams:\n",
      ". trip\n",
      ". easy\n",
      "  . Most correlated bigrams:\n",
      ". trip advisor\n",
      ". easy use\n",
      "# 'Rating':\n",
      "  . Most correlated unigrams:\n",
      ". nice\n",
      ". good\n",
      "  . Most correlated bigrams:\n",
      ". good good\n",
      ". information technology\n",
      "# 'UserExperience':\n",
      "  . Most correlated unigrams:\n",
      ". fix\n",
      ". crash\n",
      "  . Most correlated bigrams:\n",
      ". update fix\n",
      ". latest update\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "for label, label_id in sorted(label_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == label_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"# '{}':\".format(label))\n",
    "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb321f0",
   "metadata": {},
   "source": [
    "## <center><font color=purple>5. Evaluation Measures <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466888b2",
   "metadata": {},
   "source": [
    "#### In our project we're going to use the classification report provided by sklearn\n",
    "#### It is a performance evaluation metric in machine learning which is used to show the precision, recall, F1 Score, and support score of your trained classification model.\n",
    "    \n",
    "    sklearn.metrics.classification_report\n",
    "#### Check [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn-metrics-classification-report) for more details \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01491c78",
   "metadata": {},
   "source": [
    "The reason this report is used because it shows the main classification metrics\n",
    "precision, recall and f1-score on a per-class basis.\n",
    "The metrics are calculated by using true and false positives, true and false negatives.\n",
    "Positive and negative in this case are generic names for the predicted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc2c26d",
   "metadata": {},
   "source": [
    "it measures the quality of predictions from a classification algorithm. How many predictions are True and how many are False. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report as will be shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a504e",
   "metadata": {},
   "source": [
    "## <center><font color=purple>6. Classifers <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae03763",
   "metadata": {},
   "source": [
    "* Naive Bayes\n",
    "* Logistic Regression\n",
    "* Support Victor Machines (Linear & SGD)\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9992b",
   "metadata": {},
   "source": [
    "**Naive Bayes**: In statistics, naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong independence assumptions between the features. They are among the simplest Bayesian network models, but coupled with kernel density estimation.\n",
    "\n",
    "**Justification**: After doing a lot of research, we found out that \n",
    "The Naive Bayesian classifier consists of performing the below steps â€“\n",
    "\n",
    "- Create a frequency table based on the words\n",
    "- Calculate the likelihood for each of the classes based on the frequency table\n",
    "- Calculate the posterior probability for each class\n",
    "- The highest posterior probability is the outcome of the prediction experiment\n",
    "\n",
    "All these probabilities are calculated by using the Bayes Theorem and this will help us in our App Reviews Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db6592",
   "metadata": {},
   "source": [
    "**Logistic Regression**: Logistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability. The Logistic Regression uses a more complex cost function, this cost function can be defined as the â€˜Sigmoid functionâ€™ or also known as the â€˜logistic functionâ€™ instead of a linear function.\n",
    "\n",
    "**Justification**: After doing a lot of research in text classification, we found out that Logistic regression is a simple and easy to understand classification algorithm, and Logistic regression can be easily generalized to multiple classes. Furthermore, it is widely used in multi-class text classification problems. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d62a96",
   "metadata": {},
   "source": [
    "**SVM**: SVM is a supervised machine learning algorithm that can be used for both classification or regression challenges. However,  it is mostly used in classification problems. In the SVM algorithm, we plot each data item as a point in n-dimensional space (where n is a number of features you have) with the value of each feature being the value of a particular coordinate.\n",
    "\n",
    "In its most simple type, SVM doesnâ€™t support multiclass classification natively. It supports binary classification and separating data points into two classes. For multiclass classification, such as, our project, the same principle is utilized after breaking down the multiclassification problem into multiple binary classification problems.\n",
    "\n",
    "**Justification**: After doing a lot of research in text classification, we found out that (SVM) has proven to be an eï¬€ective multiclass text classiï¬er. \"In 1997 Joachims published results on a set of binary text classiï¬cation experiments using the Support Vector Machine. The SVM yielded lower error than many other classiï¬cation techniques\".\n",
    "\n",
    "Moreover, two other scientists followed two years later with experiments of their own on the same data set. They used improved versions of other classifiers but still found that the SVM performed at least as well as all other classiï¬ers they tried, and for that reason we have decided to try both linear SVM & SGD to trsin SVM in our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd50ee4",
   "metadata": {},
   "source": [
    "**Random Forest**: A random forest is a machine learning technique that's used to solve regression and classification problems. It utilizes ensemble learning, which is a technique that combines many classifiers to provide solutions to complex problems. A random forest algorithm consists of many decision trees.\n",
    "\n",
    "**Justification**: Random Forests are an ensemble method which trains a bunch of decision trees (hence the â€˜forestâ€™) to try and combat overfitting which decision trees are prone to. It does this by averaging the predictions of the different decision trees which can reduce the variance. Tuning models is all about finding the best balance between bias and variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa26a49",
   "metadata": {},
   "source": [
    "## <center><font color=purple>7. Hyper-parameter Tuning <a class=\"anchor\" id=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a967784",
   "metadata": {},
   "source": [
    "#### In this section we've pipelined all of our classifiers to automate the process of tunning the paramters using GridSearchCV , \n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8086cad",
   "metadata": {},
   "source": [
    "#### If you want to know the results of GridSearchCV use,\n",
    "\n",
    "    clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b639b",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbb63c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           Bug     0.8992    0.9692    0.9329       681\n",
      "       Feature     0.8403    0.9582    0.8954       670\n",
      "        Rating     0.8171    0.6059    0.6959       708\n",
      "UserExperience     0.7807    0.8192    0.7995       730\n",
      "\n",
      "      accuracy                         0.8351      2789\n",
      "     macro avg     0.8343    0.8381    0.8309      2789\n",
      "  weighted avg     0.8332    0.8351    0.8288      2789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB())])\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__stop_words':['english'],\n",
    "    'vect__encoding':['latin-1'],\n",
    "    'vect__min_df':[1,2,3],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2,1e-3,1e-4]\n",
    "}\n",
    "#tuned_parameters = {}\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=5, scoring=\"accuracy\")\n",
    "clf.fit(trainx, trainy)\n",
    "\n",
    "print(classification_report(testy, clf.predict(testx), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3aa7b5",
   "metadata": {},
   "source": [
    "## Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab637254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           Bug     0.9235    0.9574    0.9402       681\n",
      "       Feature     0.9167    0.9030    0.9098       670\n",
      "        Rating     0.7113    0.7585    0.7341       708\n",
      "UserExperience     0.7934    0.7260    0.7582       730\n",
      "\n",
      "      accuracy                         0.8333      2789\n",
      "     macro avg     0.8362    0.8362    0.8356      2789\n",
      "  weighted avg     0.8339    0.8333    0.8329      2789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using logistic regression as a classification model using Spark\n",
    "# Building the model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(random_state=0, C=1e5)),\n",
    "               ])\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__stop_words':['english'],\n",
    "    'vect__encoding':['latin-1'],\n",
    "    'vect__min_df':[1,2,3],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__n_jobs': [1,2],\n",
    "}\n",
    "\n",
    "# Fitting the model built above in the training set and then testing it\n",
    "# and printing different reports along with the accuracy \n",
    "from sklearn.metrics import classification_report\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=5, scoring=\"accuracy\")\n",
    "clf.fit(trainx, trainy)\n",
    "\n",
    "print(classification_report(testy, clf.predict(testx), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31e0b4",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a0e40",
   "metadata": {},
   "source": [
    "#### A) SVM with SGD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5117e84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           Bug     0.9233    0.9721    0.9471       681\n",
      "       Feature     0.8859    0.9731    0.9275       670\n",
      "        Rating     0.8194    0.7048    0.7578       708\n",
      "UserExperience     0.8102    0.8068    0.8085       730\n",
      "\n",
      "      accuracy                         0.8612      2789\n",
      "     macro avg     0.8597    0.8642    0.8602      2789\n",
      "  weighted avg     0.8583    0.8612    0.8580      2789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(random_state=42)),\n",
    "               ])\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__stop_words':['english'],\n",
    "    'vect__encoding':['latin-1'],\n",
    "    'vect__min_df':[1,2,3],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2,1e-3,1e-4],\n",
    "    'clf__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'clf__penalty':['l2', 'l1', 'elasticnet'],\n",
    "    'clf__max_iter': [1000,2000,3000]\n",
    "}\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=5, scoring=\"accuracy\")\n",
    "clf.fit(trainx, trainy)\n",
    "\n",
    "print(classification_report(testy, clf.predict(testx), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054e75d",
   "metadata": {},
   "source": [
    "#### B) Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93159da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           Bug     0.9057    0.9736    0.9384       681\n",
      "       Feature     0.9050    0.9522    0.9280       670\n",
      "        Rating     0.7883    0.7415    0.7642       708\n",
      "UserExperience     0.8236    0.7740    0.7980       730\n",
      "\n",
      "      accuracy                         0.8573      2789\n",
      "     macro avg     0.8557    0.8603    0.8572      2789\n",
      "  weighted avg     0.8542    0.8573    0.8549      2789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LinearSVC(random_state=42)),\n",
    "               ])\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__stop_words':['english'],\n",
    "    'vect__encoding':['latin-1'],\n",
    "    'vect__min_df':[1,2,3],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'clf__penalty':['l2', 'l1'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "## Testing the model and printing the accuracy\n",
    "regr.fit(trainx, trainy)\n",
    "print(classification_report(testy, regr.predict(testx), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c642",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d160929",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           Bug     0.7397    0.7386    0.7392       681\n",
      "       Feature     0.6787    0.7597    0.7169       670\n",
      "        Rating     0.5967    0.7669    0.6712       708\n",
      "UserExperience     0.7261    0.4466    0.5530       730\n",
      "\n",
      "      accuracy                         0.6744      2789\n",
      "     macro avg     0.6853    0.6780    0.6701      2789\n",
      "  weighted avg     0.6852    0.6744    0.6678      2789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(random_state=0)),\n",
    "               ])\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__stop_words':['english'],\n",
    "    'vect__encoding':['latin-1'],\n",
    "    'vect__min_df':[1,2,3],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_depth': [3,4,5],\n",
    "    'clf__n_estimators':[200, 300],\n",
    "}\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=5, scoring=\"accuracy\")\n",
    "clf.fit(trainx, trainy)\n",
    "\n",
    "print(classification_report(testy, clf.predict(testx), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34edb14",
   "metadata": {},
   "source": [
    "## <font color=orange> Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34ab59",
   "metadata": {},
   "source": [
    "#### <font color=orange>Undersampling using our method without libraries performed around 43% accuracy.\n",
    "        undersample(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeba1e8",
   "metadata": {},
   "source": [
    "#### <font color=orange>Use,\n",
    "    \n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "#### <font color=orange>Then include it as follows:\n",
    "\n",
    "        text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('RUS', RandomOverSampler()),  *OR*  ('RUS', RandomUnderSampler()), \n",
    "                        ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8fe5d",
   "metadata": {},
   "source": [
    "#### <font color=orange>Undersampling using library resulted in around 50% accuracy \n",
    "#### <font color=orange>Oversampling performed better at around 64% accuracy\n",
    "#### <font color=orange>However, our best result was through data augmenting by generating new parapharsed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce8dbe",
   "metadata": {},
   "source": [
    "## <center><font color=purple>8. Error Analysis & Possible Improvements <a class=\"anchor\" id=\"eighth-bullet\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab25993",
   "metadata": {},
   "source": [
    "* Oversampling Training data only instead of the whole dataset. \n",
    "\n",
    "Copies of the same point may end up in both the training and test sets. This allows the classifier to cheat, because when trying to make predictions on the test set the classifier will already have seen identical points in the train set. However, in our project we believe that it should not effect much since we have a small data and we have done data preprocessing and deleted replicated data (if any). \n",
    "<hr>\n",
    "\n",
    "* In RandomForest we could see that it performs worse than most classifer, even though it shouldn't.\n",
    "    This is because we're using a basic estimaitor, using tunned base_estimators would definility results an exceeding performance.\n",
    "\n",
    "<hr>\n",
    "\n",
    "* Using different text augmentation\n",
    "    \n",
    "Data augmentation is a data oversampling technique used to increase the size of the data by adding new samples that have a similar distribution to the original data or marginally altering the original data. The data needs to be altered in a way that preserves the class label for better performance at the classification task.\n",
    "\n",
    "A possible improvment is using diffrent techniques, such as:\n",
    "   \n",
    "Different Synonym Word Replacement    \n",
    "    - Word Embedding based Replacement: Pretrained word embedding like GloVe.\n",
    "    - Lexical based Replacement: Wordnet\n",
    "    \n",
    "Generative Models\n",
    "    Generative language models such as BERT, RoBERTa, BART or the recent T5 model can be used to generate the text in a more class label preserving manner. The generative model encodes the class label along with its associated text sequences to generate newer samples with some modifications. The approach is usually more reliable and the sample generated are more representative of the associated class label.\n",
    "    \n",
    "Random Insertion / Swapping / Deletion\n",
    "    - Random Insertion: Identifying and extracting synonyms for some randomly chosen words that are not StopWords in \n",
    "    the sentence. Inserting this identified synonym at some random position in the sentence.\n",
    "    \n",
    "    - Random Swapping: Randomly choosing two words in the sentence and swap their positions. This may not be a good \n",
    "    idea in a morphologically rich language like Hindi, Marathi as it may entirely change the meaning of the sentence.\n",
    "    \n",
    "    - Random Deletion: Randomly removing word in the sentence.\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44455df0",
   "metadata": {},
   "source": [
    "## <center><font color=purple>9. Final Results <a class=\"anchor\" id=\"ninth-bullet\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46989a0",
   "metadata": {},
   "source": [
    "| Classifier| Accuracy |  |\n",
    "| --- | --- | --- |\n",
    "| Naive Bayes |  | 0.8351       |\n",
    "| Logisitc Regression |  | 0.8333       |\n",
    "| SVM SGD |  | 0.8612       |\n",
    "| SVM Linear |  | 0.8573       |\n",
    "| RandomForest |  | 0.6744       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d4f08",
   "metadata": {},
   "source": [
    "- Naive Bayes: Achieved accuracy score of 83.51%.\n",
    "- Logistic Regression: Achieved a lower accuracy score of 83.33%.\n",
    "- SVM SGD: Achieved a higher accuracy score of 86.12% which is approximately 3% improvement over Naive Bayes.\n",
    "- SVM Linear: Achieved a high accuracy score of 85.73% which is approximately 2% improvement over Naive Bayes but slightly less than SGD.\n",
    "- Random Forest: Achieved accuracy score of 67.44% which is the least score between all classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a31c74",
   "metadata": {},
   "source": [
    "## <center><font color=purple>10. Conclusion <a class=\"anchor\" id=\"tenth-bullet\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e016afc",
   "metadata": {},
   "source": [
    "In conclusion, we have done some data preprocessing on the App Reviews dataset, such as, data cleaning, data transformation. Unbalanced data were dealt with by using both data oversampling & undersampling. Moreover, few evaluation measures were used from the classification report, such as, precision, recall, F1 Score, and support score.\n",
    "\n",
    "Four classifers were used in our project, Naive Bayes, Logistic Regression, SVM and Random Forest, with almost similar accuracy between them. Furthermore, we have shown that the Support Vector Machine can perform multiclass text classiï¬cation very eï¬€ectively and slightly better than Naive Bayes and Logistic Regression. Moreover, hyperparameter optimization or tuning using GridSearchCV gave us a better result on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a9aa7",
   "metadata": {},
   "source": [
    "# <font color=blue> Resources: Here is a list of diffrent articles & research the we have used in our project\n",
    "    \n",
    "    \n",
    "* https://analyticsindiamag.com/naive-bayes-why-is-it-favoured-for-text-related-tasks/\n",
    "* https://www.researchgate.net/publication/2522390_Improving_Multiclass_Text_Classification_with_the_Support_Vector_Machine\n",
    "* https://www.baeldung.com/cs/svm-multiclass-classification\n",
    "* https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/\n",
    "* https://muthu.co/understanding-the-classification-report-in-sklearn/\n",
    "* https://saurabhk30.medium.com/5-data-augmentation-techniques-for-text-classification-d14f6d8bd6aa\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
